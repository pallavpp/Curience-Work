{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# natural language processing\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links\n",
    "curr_path = os.path.abspath(\"testing_tfidf_glamour_magazine.ipynb\")\n",
    "df_path = os.path.abspath(os.path.join(curr_path, \"../../..\", \"Read_Files/fashion_intern_forecasting_website_list.csv\"))\n",
    "df = pd.read_csv(df_path)\n",
    "count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all stopwords\n",
    "additional_stopwords = []\n",
    "stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean up the passed text.\\n\n",
    "    All words are lemmatized afte encoding and basic regex parsing is performed.\\n\n",
    "    \\n\n",
    "    Parameters:\n",
    "    text - Text to be worked with\n",
    "    \"\"\"\n",
    "\n",
    "    # lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "\n",
    "    # word list\n",
    "    return \" \".join([wnl.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document corpus\n",
    "document_corpus = []\n",
    "successful_blog_list = []\n",
    "for i in range(count):\n",
    "    # blog link\n",
    "    blog_link = df[\"Website URL\"][i]\n",
    "\n",
    "    # getting page content\n",
    "    html_response = requests.get(blog_link)\n",
    "    if html_response.status_code != 200:\n",
    "        continue\n",
    "\n",
    "    # get soup object\n",
    "    html_text = html_response.text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # get all text\n",
    "    all_text = [element.text.strip() for element in soup.find_all([\"p\", \"span\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "\n",
    "    document_corpus.append(clean_text(text=\" \".join(all_text)))\n",
    "    successful_blog_list.append(blog_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get tfidf scoring\n",
    "def get_scores(corpus=document_corpus, n=1, m=1):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords, ngram_range=(n, m))\n",
    "    tfIdf = vectorizer.fit_transform(corpus)\n",
    "    for blog in successful_blog_list:\n",
    "        if(blog == \"https://www.glamourmagazine.co.uk/gallery/spring-summer-2022-fashion-trends\"):\n",
    "            df = pd.DataFrame(tfIdf[0].T.todense(), index=vectorizer.get_feature_names_out(), columns=[\"Score\"])\n",
    "            df = df.sort_values(\"Score\", ascending=False)\n",
    "    print(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:\n",
      "                 Score\n",
      "courtesy      0.342646\n",
      "revolve       0.231841\n",
      "perfect       0.209135\n",
      "dress         0.198596\n",
      "eloquii       0.185473\n",
      "youll         0.140060\n",
      "bra           0.139423\n",
      "look          0.126379\n",
      "fringe        0.112486\n",
      "2022          0.108325\n",
      "cutout        0.106935\n",
      "party         0.093449\n",
      "virgile       0.092737\n",
      "em            0.092737\n",
      "gorgeous      0.092737\n",
      "volume        0.092737\n",
      "im            0.092737\n",
      "intermix      0.092737\n",
      "sleeve        0.092737\n",
      "effortlessly  0.092737\n",
      "black         0.084364\n",
      "fashion       0.083045\n",
      "top           0.083045\n",
      "trend         0.083045\n",
      "stunning      0.079268\n"
     ]
    }
   ],
   "source": [
    "# get scores 1-grams\n",
    "print(\"1-grams:\")\n",
    "get_scores(n=1, m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams:\n",
      "                      Score\n",
      "dress courtesy     0.142446\n",
      "youll seeing       0.094964\n",
      "victor virgile     0.094964\n",
      "dress eloquii      0.094964\n",
      "dress made         0.094964\n",
      "seeing everywhere  0.094964\n",
      "effortlessly cool  0.094964\n",
      "lowrise jean       0.081172\n",
      "bra top            0.081172\n",
      "crop top           0.071386\n",
      "trend youll        0.057594\n",
      "fashion trend      0.047808\n",
      "top courtesy       0.047482\n",
      "cute cardigan      0.047482\n",
      "princess polly     0.047482\n",
      "cutout pair        0.047482\n",
      "better puff        0.047482\n",
      "better stunning    0.047482\n",
      "cut estrop         0.047482\n",
      "top ha             0.047482\n",
      "910 revolve        0.047482\n",
      "cutout moment      0.047482\n",
      "wear plain         0.047482\n",
      "mini perfect       0.047482\n",
      "cutout knit        0.047482\n"
     ]
    }
   ],
   "source": [
    "# get scores 2-grams\n",
    "print(\"2-grams:\")\n",
    "get_scores(n=2, m=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-grams:\n",
      "                                  Score\n",
      "trend youll seeing             0.095447\n",
      "youll seeing everywhere        0.095447\n",
      "fashion trend youll            0.071749\n",
      "225 revolve love               0.047723\n",
      "linen bralette courtesy        0.047723\n",
      "gettyjeremy moeller im         0.047723\n",
      "chicest trend sure             0.047723\n",
      "reign 2022 hint                0.047723\n",
      "estrop statementmaking cutout  0.047723\n",
      "course youll also              0.047723\n",
      "metallic dress perfect         0.047723\n",
      "resurgence y2k fashion         0.047723\n",
      "298 intermix gorgeous          0.047723\n",
      "link page recommend            0.047723\n",
      "function versace sequin        0.047723\n",
      "whether youre searching        0.047723\n",
      "sorbet colored mini            0.047723\n",
      "275 intermix puffsleeve        0.047723\n",
      "lioness 59 princess            0.047723\n",
      "vaquera 14 fringe              0.047723\n",
      "vanades frill crop             0.047723\n",
      "bougie event cut               0.047723\n",
      "throw oversized buttondown     0.047723\n",
      "check shoe bag                 0.047723\n",
      "much whether youre             0.047723\n"
     ]
    }
   ],
   "source": [
    "# get scores 3-grams\n",
    "print(\"3-grams:\")\n",
    "get_scores(n=3, m=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed:\n",
      "                            Score\n",
      "courtesy                 0.201290\n",
      "revolve                  0.136197\n",
      "perfect                  0.122858\n",
      "dress                    0.116667\n",
      "eloquii                  0.108958\n",
      "youll                    0.082279\n",
      "bra                      0.081905\n",
      "dress courtesy           0.081718\n",
      "look                     0.074242\n",
      "fringe                   0.066081\n",
      "2022                     0.063636\n",
      "cutout                   0.062820\n",
      "party                    0.054897\n",
      "sleeve                   0.054479\n",
      "intermix                 0.054479\n",
      "seeing everywhere        0.054479\n",
      "victor virgile           0.054479\n",
      "dress eloquii            0.054479\n",
      "virgile                  0.054479\n",
      "effortlessly             0.054479\n",
      "effortlessly cool        0.054479\n",
      "youll seeing everywhere  0.054479\n",
      "youll seeing             0.054479\n",
      "volume                   0.054479\n",
      "gorgeous                 0.054479\n"
     ]
    }
   ],
   "source": [
    "# get mixed scores\n",
    "print(\"Mixed:\")\n",
    "get_scores(n=1, m=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473418c0e77683684e48f36ee0a4eb17769bc02766a503d3556a3480c1d685e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
