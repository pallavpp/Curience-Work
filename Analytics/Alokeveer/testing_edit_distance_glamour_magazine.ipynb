{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import module \n",
    "import requests \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# natural language processing: n-gram ranking\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all stopwords\n",
    "additional_stopwords = []\n",
    "stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup text and find words in it\n",
    "def extract_words_from_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean up the passed text.\\n\n",
    "    All words that are not designated as a stop word are lemmatized afte encoding and basic regex parsing is performed.\\n\n",
    "    \\n\n",
    "    Parameters:\n",
    "    text - Text to be worked with\n",
    "    keywords_excluded - 'True' if keywords are to be treaded as stopwords\n",
    "    \"\"\"\n",
    "\n",
    "    # lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "\n",
    "    # word list\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vocabulary():\n",
    "    curr_path = os.path.abspath(\"testing_tfidf_glamour_magazine.ipynb\")\n",
    "    df_path = os.path.abspath(os.path.join(curr_path, \"../../..\", \"Read_Files/fashion_vocabulary.csv\"))\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    vocabulary_list = [v for v in df['Specifications']]\n",
    "\n",
    "    return vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(words, vocabulary):\n",
    "    lis = []\n",
    "    \n",
    "    for extracted_word in words:\n",
    "        for vocab in vocabulary:\n",
    "            cnt = 0\n",
    "            for i in range(max(len(vocab), len(extracted_word))):\n",
    "                if i >= len(vocab) or i >= len(extracted_word):\n",
    "                    cnt += 1\n",
    "                elif vocab[i] != extracted_word[i]:\n",
    "                    cnt += 1\n",
    "            \n",
    "            lis.append([vocab, extracted_word, cnt])\n",
    "\n",
    "    df = pd.DataFrame(lis, columns=[\"Vocaubulary\", \"Extracted word\", \"Edit distance\"])\n",
    "    df.sort_values(by=\"Edit distance\", inplace=True)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    all_matching_words = set()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"Edit distance\"] == 0:\n",
    "            all_matching_words.add(row[\"Extracted word\"])\n",
    "    \n",
    "    print(all_matching_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting page content\n",
    "html_response = requests.get(\"https://www.glamourmagazine.co.uk/gallery/spring-summer-2022-fashion-trends\")\n",
    "html_text = html_response.text\n",
    "soup = BeautifulSoup(html_text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various sources of text\n",
    "para_text = [element.text.strip() for element in soup.find_all(\"p\")]\n",
    "header_text = [element.text.strip() for element in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "span_text = [element.text.strip() for element in soup.find_all(\"span\")]\n",
    "all_text = para_text + header_text + span_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Vocaubulary Extracted word  Edit distance\n",
      "213926                       spring         spring              0\n",
      "335098                       summer         summer              0\n",
      "29265                        button         button              0\n",
      "167139                      pleated        pleated              0\n",
      "163180                        plain          plain              0\n",
      "...                             ...            ...            ...\n",
      "507507  three quarter length sleeve        fashion             27\n",
      "124722  three quarter length sleeve      dominated             27\n",
      "232206  three quarter length sleeve         length             27\n",
      "479622  three quarter length sleeve            hit             27\n",
      "0       three quarter length sleeve        product             27\n",
      "\n",
      "[547560 rows x 3 columns]\n",
      "{'black', 'long', 'top', 'skirt', 'sheer', 'summer', 'cropped', 'midi', 'pleated', 'lace', 'gold', 'sexy', 'silver', 'yes', 'spring', 'straight', 'metallic', 'beige', 'mini', 'crochet', 'yellow', 'vest', 'pink', 'white', 'coat', 'winter', 'plain', 'button', 'blazer'}\n"
     ]
    }
   ],
   "source": [
    "words = extract_words_from_text(text=\" \".join(all_text))\n",
    "vocabulary = extract_vocabulary()\n",
    "edit_distance(words=words, vocabulary=vocabulary)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
