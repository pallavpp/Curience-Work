{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# natural language processing\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas display settings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.width = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and store all keywords in lowercase\n",
    "stopwords_path = os.path.abspath(os.path.join(os.path.abspath(\"test.ipynb\"), \"../../../../Read_Files\", \"stopwords_cleaned.txt\"))\n",
    "with open(stopwords_path) as file:\n",
    "    stopwords = [line.strip().lower() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store all ntlk stopwords\n",
    "# additional_stopwords = []\n",
    "# stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    # words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    words = re.sub(r'[^a-zA-Z\\s]+', '', text).split()\n",
    "\n",
    "    # word list\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get all page content from html response\n",
    "def get_page_text(html_response):\n",
    "    # getting page content\n",
    "    html_text = html_response.text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    \n",
    "    # various sources of text\n",
    "    para_text = [element.text.strip() for element in soup.find_all(\"p\")]\n",
    "    header_text = [element.text.strip() for element in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "    span_text = [element.text.strip() for element in soup.find_all(\"span\")]\n",
    "    all_text = para_text + header_text + span_text\n",
    "    \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.vogue.co.uk/fashion/gallery/spring-summer-2022-fashion-trends\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting page response\n",
    "html_response = requests.get(url)\n",
    "if(html_response.status_code == 200):\n",
    "    # get page content\n",
    "    all_text = \" \".join(get_page_text(html_response))\n",
    "    # filter all sentences\n",
    "    final_text = clean_text(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, 'yumi nu')\n",
      "(4.0, 'youre interested')\n",
      "(4.0, 'young designers')\n",
      "(4.0, 'young designer')\n",
      "(4.0, 'worn low')\n",
      "(4.0, 'wiped completely')\n",
      "(4.0, 'wind embracing')\n",
      "(4.0, 'wild buckle')\n",
      "(4.0, 'whole thing')\n",
      "(4.0, 'vivienne westwood')\n",
      "(4.0, 'valentino updates')\n",
      "(4.0, 'unsolicited appearance')\n",
      "(4.0, 'underwearasouterwear renditions')\n",
      "(4.0, 'tonal shades')\n",
      "(4.0, 'tiny strips')\n",
      "(4.0, 'tiktok generation')\n",
      "(4.0, 'tangerine tangoed')\n",
      "(4.0, 'sweet release')\n",
      "(4.0, 'sure weve')\n",
      "(4.0, 'supriya lele')\n",
      "(4.0, 'super short')\n",
      "(4.0, 'structured blazer')\n",
      "(4.0, 'strange anymore')\n",
      "(4.0, 'spring bringing')\n",
      "(4.0, 'slightest excuse')\n",
      "(4.0, 'size wasnt')\n",
      "(4.0, 'siren song')\n",
      "(4.0, 'single strap')\n",
      "(4.0, 'similarly comfortdriven')\n",
      "(4.0, 'show notes')\n",
      "(4.0, 'sheer tights')\n",
      "(4.0, 'sexy comes')\n",
      "(4.0, 'seen since')\n",
      "(4.0, 'secondskin takes')\n",
      "(4.0, 'say hello')\n",
      "(4.0, 'saint laurent')\n",
      "(4.0, 'revolving doors')\n",
      "(4.0, 'relied upon')\n",
      "(4.0, 'recent seasons')\n",
      "(4.0, 'proud imagine')\n",
      "(4.0, 'pradas collection')\n",
      "(4.0, 'prabal gurung')\n",
      "(4.0, 'porn site')\n",
      "(4.0, 'poked fun')\n",
      "(4.0, 'play rothko')\n",
      "(4.0, 'past september')\n",
      "(4.0, 'particularly enticing')\n",
      "(4.0, 'oversized fit')\n",
      "(4.0, 'outre take')\n",
      "(4.0, 'odd pair')\n",
      "(4.0, 'nipples invest')\n",
      "(4.0, 'newseason icons')\n",
      "(4.0, 'multiple zips')\n",
      "(4.0, 'mullet hems')\n",
      "(4.0, 'mood taking')\n",
      "(4.0, 'miu miu')\n",
      "(4.0, 'may well')\n",
      "(4.0, 'lump together')\n",
      "(4.0, 'louis vuitton')\n",
      "(4.0, 'london occasionally')\n",
      "(4.0, 'indemand models')\n",
      "(4.0, 'idiosyncratic takes')\n",
      "(4.0, 'hotvax summer')\n",
      "(4.0, 'hottest product')\n",
      "(4.0, 'hems chopped')\n",
      "(4.0, 'hedonistic approach')\n",
      "(4.0, 'headtotoe inspired')\n",
      "(4.0, 'good tailoring')\n",
      "(4.0, 'fringe feels')\n",
      "(4.0, 'frenetic energy')\n",
      "(4.0, 'found much')\n",
      "(4.0, 'follow us')\n",
      "(4.0, 'fluid dress')\n",
      "(4.0, 'finally wising')\n",
      "(4.0, 'feminine ease')\n",
      "(4.0, 'feeling sexy')\n",
      "(4.0, 'fashions walk')\n",
      "(4.0, 'fashions got')\n",
      "(4.0, 'exit proliferate')\n",
      "(4.0, 'exit come')\n",
      "(4.0, 'every skirt')\n",
      "(4.0, 'erotic portion')\n",
      "(4.0, 'enough want')\n",
      "(4.0, 'emilia wickstead')\n",
      "(4.0, 'ellie pithers')\n",
      "(4.0, 'early read')\n",
      "(4.0, 'dressmaking shears')\n",
      "(4.0, 'dress codes')\n",
      "(4.0, 'donatella versace')\n",
      "(4.0, 'dominate come')\n",
      "(4.0, 'dolce gabbana')\n",
      "(4.0, 'distressed finish')\n",
      "(4.0, 'diagonals wafting')\n",
      "(4.0, 'demure kittenheels')\n",
      "(4.0, 'delicious effect')\n",
      "(4.0, 'deepblue denim')\n",
      "(4.0, 'daring vein')\n",
      "(4.0, 'could forgo')\n",
      "(4.0, 'cotton pants')\n",
      "(4.0, 'conventional interpretations')\n",
      "(4.0, 'comfortable pair')\n",
      "(4.0, 'colour combinations')\n",
      "(4.0, 'collections even')\n",
      "(4.0, 'collection made')\n",
      "(4.0, 'clinical takes')\n",
      "(4.0, 'christian siriano')\n",
      "(4.0, 'catwalks look')\n",
      "(4.0, 'capes ripe')\n",
      "(4.0, 'cameras like')\n",
      "(4.0, 'calling card')\n",
      "(4.0, 'boymeetsgirl combination')\n",
      "(4.0, 'body stockings')\n",
      "(4.0, 'body positivity')\n",
      "(4.0, 'blockbuster show')\n",
      "(4.0, 'biker jacket')\n",
      "(4.0, 'big boys')\n",
      "(4.0, 'anyone dares')\n",
      "(4.0, 'alice cary')\n",
      "(4.0, 'alexander mcqueen')\n",
      "(4.0, 'ages adapting')\n",
      "(4.0, 'afterdark glamour')\n"
     ]
    }
   ],
   "source": [
    "# Uses stopwords for english from NLTK, and all puntuation characters by default\n",
    "r = Rake(min_length=2, max_length=2, include_repeated_phrases=False)\n",
    "# Extraction given the text.\n",
    "r.extract_keywords_from_text(final_text)\n",
    "# To get keyword phrases ranked highest to lowest.\n",
    "keywords = r.get_ranked_phrases_with_scores()\n",
    "for keyword in keywords:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473418c0e77683684e48f36ee0a4eb17769bc02766a503d3556a3480c1d685e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
