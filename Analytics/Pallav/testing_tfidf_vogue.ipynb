{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# natural language processing\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links\n",
    "curr_path = os.path.abspath(\"testing_tfidf_vogue.ipynb\")\n",
    "df_path = os.path.abspath(os.path.join(curr_path, \"../../..\", \"Read_Files/fashion_intern_forecasting_website_list.csv\"))\n",
    "df = pd.read_csv(df_path)\n",
    "count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all stopwords\n",
    "additional_stopwords = []\n",
    "stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean up the passed text.\\n\n",
    "    All words are lemmatized afte encoding and basic regex parsing is performed.\\n\n",
    "    \\n\n",
    "    Parameters:\n",
    "    text - Text to be worked with\n",
    "    \"\"\"\n",
    "\n",
    "    # lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "\n",
    "    # word list\n",
    "    return \" \".join([wnl.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document corpus\n",
    "document_corpus = []\n",
    "successful_blog_list = []\n",
    "for i in range(count):\n",
    "    # blog link\n",
    "    blog_link = df[\"Website URL\"][i]\n",
    "\n",
    "    # getting page content\n",
    "    html_response = requests.get(blog_link)\n",
    "    if html_response.status_code != 200:\n",
    "        continue\n",
    "\n",
    "    # get soup object\n",
    "    html_text = html_response.text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # get all text\n",
    "    all_text = [element.text.strip() for element in soup.find_all([\"p\", \"span\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "\n",
    "    document_corpus.append(clean_text(text=\" \".join(all_text)))\n",
    "    successful_blog_list.append(blog_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get tfidf scoring\n",
    "def get_scores(corpus=document_corpus, n=1, m=1):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords, ngram_range=(n, m))\n",
    "    tfIdf = vectorizer.fit_transform(corpus)\n",
    "    for blog in successful_blog_list:\n",
    "        if(blog == \"https://www.vogue.co.uk/fashion/gallery/spring-summer-2022-fashion-trends\"):\n",
    "            df = pd.DataFrame(tfIdf[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"Score\"])\n",
    "            df = df.sort_values(\"Score\", ascending=False)\n",
    "    print(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:\n",
      "                 Score\n",
      "courtesy      0.342385\n",
      "revolve       0.231665\n",
      "perfect       0.208976\n",
      "dress         0.198445\n",
      "eloquii       0.185332\n",
      "youll         0.139954\n",
      "bra           0.139317\n",
      "look          0.126283\n",
      "fringe        0.112400\n",
      "2022          0.108243\n",
      "cutout        0.106854\n",
      "party         0.104488\n",
      "virgile       0.092666\n",
      "effortlessly  0.092666\n",
      "sleeve        0.092666\n",
      "volume        0.092666\n",
      "im            0.092666\n",
      "gorgeous      0.092666\n",
      "intermix      0.092666\n",
      "em            0.092666\n",
      "black         0.084300\n",
      "fashion       0.082982\n",
      "trend         0.082982\n",
      "top           0.082982\n",
      "stunning      0.079208\n"
     ]
    }
   ],
   "source": [
    "# get scores 1-grams\n",
    "print(\"1-grams:\")\n",
    "get_scores(n=1, m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams:\n",
      "                              Score\n",
      "dress courtesy             0.142483\n",
      "seeing everywhere          0.094989\n",
      "dress eloquii              0.094989\n",
      "victor virgile             0.094989\n",
      "effortlessly cool          0.094989\n",
      "youll seeing               0.094989\n",
      "dress made                 0.094989\n",
      "bra top                    0.081193\n",
      "lowrise jean               0.081193\n",
      "crop top                   0.071405\n",
      "trend youll                0.057609\n",
      "fashion trend              0.047820\n",
      "sorbet colored             0.047494\n",
      "summer bra                 0.047494\n",
      "sign may                   0.047494\n",
      "ryder fringe               0.047494\n",
      "check shoe                 0.047494\n",
      "metallic dress             0.047494\n",
      "cosmopolitan participates  0.047494\n",
      "im still                   0.047494\n",
      "quick cantmiss             0.047494\n",
      "50 zara                    0.047494\n",
      "partyready time            0.047494\n",
      "im sure                    0.047494\n",
      "west 213                   0.047494\n"
     ]
    }
   ],
   "source": [
    "# get scores 2-grams\n",
    "print(\"2-grams:\")\n",
    "get_scores(n=2, m=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-grams:\n",
      "                            Score\n",
      "youll seeing everywhere  0.095447\n",
      "trend youll seeing       0.095447\n",
      "fashion trend youll      0.071749\n",
      "looking perfect party    0.047723\n",
      "versace sequin mini      0.047723\n",
      "already even though      0.047723\n",
      "knit dress eloquii       0.047723\n",
      "fe noel 298              0.047723\n",
      "also find resurgence     0.047723\n",
      "courtesy lioness 59      0.047723\n",
      "courtesy laquan smith    0.047723\n",
      "courtesy grlfrnd 225     0.047723\n",
      "courtesy rhode 395       0.047723\n",
      "courtesy fe noel         0.047723\n",
      "courtesy eloquii 68      0.047723\n",
      "rejoice 2022 brings      0.047723\n",
      "courtesy central park    0.047723\n",
      "sorbet colored mini      0.047723\n",
      "courtesy anine bing      0.047723\n",
      "faux leather jacket      0.047723\n",
      "courtesy zara 50         0.047723\n",
      "nassir zadeh 11          0.047723\n",
      "virgile volume better    0.047723\n",
      "volume better puff       0.047723\n",
      "sleeve cutout gown       0.047723\n"
     ]
    }
   ],
   "source": [
    "# get scores 3-grams\n",
    "print(\"3-grams:\")\n",
    "get_scores(n=3, m=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed:\n",
      "                            Score\n",
      "courtesy                 0.201254\n",
      "revolve                  0.136173\n",
      "perfect                  0.122836\n",
      "dress                    0.116646\n",
      "eloquii                  0.108938\n",
      "youll                    0.082265\n",
      "bra                      0.081891\n",
      "dress courtesy           0.081704\n",
      "look                     0.074229\n",
      "fringe                   0.066069\n",
      "2022                     0.063625\n",
      "cutout                   0.062809\n",
      "party                    0.061418\n",
      "virgile                  0.054469\n",
      "intermix                 0.054469\n",
      "youll seeing             0.054469\n",
      "dress made               0.054469\n",
      "victor virgile           0.054469\n",
      "gorgeous                 0.054469\n",
      "em                       0.054469\n",
      "effortlessly             0.054469\n",
      "effortlessly cool        0.054469\n",
      "volume                   0.054469\n",
      "im                       0.054469\n",
      "youll seeing everywhere  0.054469\n"
     ]
    }
   ],
   "source": [
    "# get mixed scores\n",
    "print(\"Mixed:\")\n",
    "get_scores(n=1, m=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473418c0e77683684e48f36ee0a4eb17769bc02766a503d3556a3480c1d685e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
