{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# natural language processing\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all links\n",
    "curr_path = os.path.abspath(\"testing_tfidf_vogue.ipynb\")\n",
    "df_path = os.path.abspath(os.path.join(curr_path, \"../../..\", \"Read_Files/fashion_intern_forecasting_website_list.csv\"))\n",
    "df = pd.read_csv(df_path)\n",
    "count = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and store all keywords in lowercase\n",
    "keywords_path = os.path.abspath(os.path.join(os.path.abspath(\"testing_ngrams_vogue.ipynb\"), \"../../..\", \"Read_Files\", \"fashion_vocabulary_keywords_list.txt\"))\n",
    "with open(keywords_path) as file:\n",
    "    keywords = [line.strip().lower() for line in file]\n",
    "keywords.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all stopwords\n",
    "additional_stopwords = []\n",
    "stopwords = nltk.corpus.stopwords.words('english') + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup text\n",
    "def clean_sentence(text):\n",
    "    \"\"\"\n",
    "    Function to clean up the passed text.\\n\n",
    "    \\n\n",
    "    Parameters:\n",
    "    text - Text to be worked with\n",
    "    \"\"\"\n",
    "\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup text\n",
    "def lemmatize_sentence(text):\n",
    "    \"\"\"\n",
    "    Function to get words from passed text.\\n\n",
    "    \\n\n",
    "    Parameters:\n",
    "    text - Text to be worked with\n",
    "    \"\"\"\n",
    "\n",
    "    # lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # get words\n",
    "    words = text.split()\n",
    "\n",
    "    # word list\n",
    "    return \" \".join([wnl.lemmatize(word) for word in words if wnl.lemmatize(word) not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get tfidf scoring\n",
    "def get_scores(corpus, n=1, m=1):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords, ngram_range=(n, m))\n",
    "    tfIdf = vectorizer.fit_transform(corpus)\n",
    "    for i in range(len(successful_blog_list)):\n",
    "        if(successful_blog_list[i] == \"https://www.vogue.co.uk/fashion/gallery/spring-summer-2022-fashion-trends\"):\n",
    "            df = pd.DataFrame(tfIdf[i].T.todense(), index=vectorizer.get_feature_names(), columns=[\"Score\"])\n",
    "            df = df.sort_values(\"Score\", ascending=False)\n",
    "    print(df.head(25))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document corpus\n",
    "document_corpus = []\n",
    "document_corpus_useful = []\n",
    "successful_blog_list = []\n",
    "for i in range(count):\n",
    "    # blog link\n",
    "    blog_link = df[\"Website URL\"][i]\n",
    "\n",
    "    # getting page content\n",
    "    html_response = requests.get(blog_link)\n",
    "    if html_response.status_code != 200:\n",
    "        continue\n",
    "    else:\n",
    "        successful_blog_list.append(blog_link)\n",
    "\n",
    "    # get soup object\n",
    "    html_text = html_response.text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # get all text\n",
    "    all_text = [element.text.strip() for element in soup.find_all([\"p\", \"span\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "\n",
    "    all_sentences = \" \".join(all_text).split('.')\n",
    "    clean_sentences = [lemmatize_sentence(clean_sentence(sentence)) for sentence in all_sentences]\n",
    "    useful_sentences = []\n",
    "    for sentence in clean_sentences:\n",
    "        for keyword in keywords:\n",
    "            if keyword in sentence:\n",
    "                useful_sentences.append(sentence)\n",
    "                break\n",
    "    document_corpus.append(\" \".join(clean_sentences))\n",
    "    document_corpus_useful.append(\" \".join(useful_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams:\n",
      "                      Score\n",
      "alexander mcqueen  0.235508\n",
      "bottega veneta     0.150978\n",
      "miu miu            0.145027\n",
      "louis vuitton      0.118024\n",
      "dolce gabbana      0.117754\n",
      "supriya lele       0.103271\n",
      "christian dior     0.100652\n",
      "mcqueen alexander  0.098128\n",
      "tom ford           0.088518\n",
      "richard quinn      0.083877\n",
      "giorgio armani     0.078503\n",
      "philosophy di      0.078503\n",
      "lorenzo serafini   0.078503\n",
      "alberta ferretti   0.078503\n",
      "veneta bottega     0.078503\n",
      "molly goddard      0.078503\n",
      "di lorenzo         0.078503\n",
      "gucci gucci        0.078503\n",
      "emilia wickstead   0.073765\n",
      "max mara           0.067101\n",
      "saint sernin       0.067101\n",
      "springsummer 2022  0.059513\n",
      "fashion trend      0.059281\n",
      "ludovic de         0.059012\n",
      "de saint           0.059012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get scores 2-grams\n",
    "print(\"2-grams:\")\n",
    "get_scores(corpus=document_corpus, n=2, m=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams:\n",
      "                      Score\n",
      "alexander mcqueen  0.238815\n",
      "miu miu            0.147064\n",
      "bottega veneta     0.136087\n",
      "louis vuitton      0.119681\n",
      "supriya lele       0.104721\n",
      "christian dior     0.102065\n",
      "mcqueen alexander  0.099506\n",
      "dolce gabbana      0.099506\n",
      "tom ford           0.089761\n",
      "richard quinn      0.085054\n",
      "lorenzo serafini   0.079605\n",
      "gucci gucci        0.079605\n",
      "philosophy di      0.079605\n",
      "giorgio armani     0.079605\n",
      "di lorenzo         0.079605\n",
      "alberta ferretti   0.079605\n",
      "veneta bottega     0.079605\n",
      "molly goddard      0.079605\n",
      "emilia wickstead   0.074801\n",
      "saint sernin       0.068043\n",
      "max mara           0.068043\n",
      "springsummer 2022  0.060349\n",
      "ludovic de         0.059840\n",
      "rejina pyo         0.059840\n",
      "de saint           0.059840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get scores 2-grams\n",
    "print(\"2-grams:\")\n",
    "get_scores(corpus=document_corpus_useful, n=2, m=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473418c0e77683684e48f36ee0a4eb17769bc02766a503d3556a3480c1d685e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
