{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_link = \"https://www.vogue.co.uk/fashion/gallery/spring-summer-2022-fashion-trends\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_response = requests.get(blog_link)\n",
    "text = \"\"\n",
    "if(html_response.status_code == 200):\n",
    "    # getting page content\n",
    "    html_text = html_response.text\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # various sources of text\n",
    "    para_text = [element.text.strip() for element in soup.find_all(\"p\")]\n",
    "    header_text = [element.text.strip() for element in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "    span_text = [element.text.strip() for element in soup.find_all(\"span\")]\n",
    "    all_text = para_text + header_text + span_text\n",
    "    \n",
    "    text = \" \".join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentences.append(sent_tokenize(text))\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "curr_path = os.path.abspath(\"test.ipynb\")\n",
    "file_path = os.path.abspath(os.path.join(curr_path, \"../../../..\", \"Read_Files/glove_embeddings\", \"glove.6B.100d.txt\"))\n",
    "f = open(file_path, encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = os.path.abspath(os.path.join(curr_path, \"../../../..\", \"Read_Files\", \"stopwords_cleaned.txt\"))\n",
    "with open(stopwords_path) as file:\n",
    "    stopwords = [line.strip().lower() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lemmatize and clean page text\n",
    "def clean_sentence(text):\n",
    "    # text cleaning\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
    "    text = text.replace(\"/\", \" \")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "\n",
    "    return \" \".join([word for word in words if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = [clean_sentence(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop tops and butterflies, Grecian draping and low-rise pants, body chains and skinny, completely useless scarves – it will be tough to resist the siren song of the 2000s come spring.\n",
      "If you’re interested in the key dress shape for spring, then just know that fashion’s got a taste for flesh.\n",
      "Nowhere was this frenetic energy more evident than at Louis Vuitton, where Nicolas Ghesquière imagined “the figure of a vampire who travels through the ages, adapting to dress codes of the era.” Think 18th-century pannier dresses with their hems chopped to reveal red satin superhero-style boots; cape-tuxedo hybrids paired with indigo jeans; gold-braid embellished waistcoats with short cargo skirts and floor-sweeping Morticia Addams capes.\n",
      "Short, sheer and second-skin takes on sexy are back.\n",
      "But, after a hot-vax summer during which young people threw their insecurities to the wind, embracing a daring vein of body positivity that had previously seemed like well-merchandised marketing spiel, designers found new ways to interpret sex.\n",
      "Read more: Autumn/Winter 2021 Fashion Trends The big boys were feeling sexy, too.\n",
      "Young guns Nensi Dojaka and Supriya Lele have made this hedonistic approach their calling card, and their sheer, body-wrapping designs made headlines in London.\n",
      "Think of the hours of enjoyment you’ll get from your pink Prada satin tail creating maximum drama in your wake.\n",
      "And at Chloé, head-to-toe white even felt bohemian; a warm, cosy antidote to more clinical takes on the trend.\n",
      "“Seduction, Stripped Down” was the title of Prada’s collection and, true to form, it poked fun at conventional interpretations of allure, exploring corsetry in itchy schoolmarmish wool and offsetting micro hemlines with demure kitten-heels.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 sentences as the summary\n",
    "for i in range(10):\n",
    "    print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "473418c0e77683684e48f36ee0a4eb17769bc02766a503d3556a3480c1d685e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
